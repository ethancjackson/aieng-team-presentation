<section class="slide" id="slide-15">
    <div class="slide-content">
        <h2 class="section-label">The Social Learning Thesis</h2>
        <p class="slide-subtitle fade-in">Why consequence-driven development matters</p>
        
        <div class="social-argument fade-in" style="--delay: 0.3">
            <div class="contrast-box">
                <div class="contrast-item problem">
                    <h4>How We Train AI</h4>
                    <p>Models are trained on <em>everything at once</em>, then pressured via RLHF 
                    to suppress undesirable behaviors. They face <strong>zero social consequences</strong> 
                    for their outputs in deployment.</p>
                </div>
                <div class="contrast-item solution">
                    <h4>How Humans Learn Values</h4>
                    <p>Children learn from early on that harmful actions lead to 
                    <strong>concrete, enforced consequences</strong>. This shapes intrinsic motivation — 
                    not just surface compliance.</p>
                </div>
            </div>
        </div>
        
        <div class="key-quote fade-in" style="--delay: 0.6">
            <blockquote class="two-beats">
                <p class="beat-1">"Alignment cannot be engineered at the 'genomic' level of AI models."</p>
                <p class="beat-2">What we <em>can</em> engineer are the <strong>environments</strong> in which adaptive behaviors emerge — 
                structuring their motivations such that <em>alignment is necessary for survival</em>.</p>
            </blockquote>
        </div>
        
        <div class="research-context fade-in" style="--delay: 0.9">
            <div class="context-items">
                <div class="context-item">
                    <strong>The risk is real:</strong> Unstructured coordination produces harmful patterns 
                    that persist across generations of new agents.
                    <span class="citation-inline">Gelpí, Tang, Jackson & Cunningham — PNAS Nexus 2025</span>
                </div>
                <div class="context-item">
                    <strong>The opportunity:</strong> Design "sandbox economies" where safe behaviors 
                    emerge through structured interaction and real consequences.
                    <span class="citation-inline">Tomašev et al. — DeepMind 2025</span>
                </div>
            </div>
        </div>
    </div>
</section>
