<section class="slide" id="slide-11">
    <div class="slide-content">
        <h2 class="section-label">Why Agents Need Rich Social Environments</h2>
        
        <div class="social-context fade-in">
            <div class="emerging-field-box">
                <h4>üî• Emerging Field: Social AI</h4>
                <p>"The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agents 
                transact and coordinate at scales and speeds beyond direct human oversight."</p>
                <p class="citation-small">‚Äî Toma≈°ev et al., "Virtual Agent Economies" (2025)</p>
            </div>
        </div>
        
        <div class="finding-grid fade-in" style="--delay: 0.4">
            <div class="finding-item mechanism">
                <h4>üß™ Our Finding (PNAS Nexus)</h4>
                <p>PPO-trained agents develop <strong>emergent stereotyping</strong> from pure reward optimization ‚Äî 
                without any individual agent being "biased."</p>
                <p class="finding-detail">Human participants showed identical dynamics.</p>
            </div>
            
            <div class="finding-item evidence">
                <h4>‚ö†Ô∏è The Privacy Problem</h4>
                <p>Agents that <strong>learn from experience</strong> introduce privacy concerns.</p>
                <p>Humans learn to <em>not leak private information</em> through social consequences. 
                How do we teach agents the same?</p>
            </div>
            
            <div class="finding-item surprise">
                <h4>üîÆ Patchwork AGI Risk</h4>
                <p>"AGI may first emerge as a patchwork system, distributed across networks of sub-AGI agents with complementary skills."</p>
                <p class="citation-small">‚Äî Toma≈°ev et al., "Distributional AGI Safety" (2025)</p>
            </div>
        </div>
        
        <div class="implication-box fade-in" style="--delay: 0.8">
            <strong>Core argument:</strong> The current paradigm of "learn everything at once, then RLHF into compliance" 
            cannot produce agents that develop appropriate values through <strong>social experience with real consequences</strong>. 
            We need a fundamentally different approach.
        </div>
    </div>
</section>
